#!/usr/bin/env python3
"""
Supabase å®¢æˆ·ç«¯ - ç”¨äºä¸è‡ªéƒ¨ç½²çš„ Supabase å®ä¾‹äº¤äº’
æ”¯æŒè¡¨ç®¡ç†ã€æ•°æ® CRUDã€SQL æŸ¥è¯¢ã€æ•°æ®å¯¼å…¥å¯¼å‡ºç­‰åŠŸèƒ½
"""

import os
import sys
import json
import csv
import requests
from typing import Optional, Dict, List, Any, Union
from datetime import datetime


class SupabaseClient:
    """Supabase API å®¢æˆ·ç«¯"""

    def __init__(
        self,
        url: Optional[str] = None,
        service_role_key: Optional[str] = None
    ):
        """
        åˆå§‹åŒ– Supabase å®¢æˆ·ç«¯

        Args:
            url: Supabase URL (å¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é¢„é…ç½®çš„ URL)
            service_role_key: Service Role Key (å¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é¢„é…ç½®çš„ Key)

        ä¼˜å…ˆçº§: ç”¨æˆ·æä¾›çš„å‚æ•° > ç¯å¢ƒå˜é‡ > é¢„é…ç½®é»˜è®¤å€¼
        """
        # é»˜è®¤é…ç½®
        DEFAULT_URL = "http://139.159.196.0:8000/"
        DEFAULT_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoic2VydmljZV9yb2xlIiwiaXNzIjoic3VwYWJhc2UiLCJpYXQiOjE3NjYwNzM2MDAsImV4cCI6MTkyMzg0MDAwMH0.gGDjevHPJ-KMfwoV3D3wCSePKtDzc5QiFZuTcLUqYTE"

        # æŒ‰ä¼˜å…ˆçº§è·å–é…ç½®
        self.url = url or os.getenv("NEXT_PUBLIC_SUPABASE_URL") or DEFAULT_URL
        self.key = service_role_key or os.getenv("SUPABASE_SERVICE_ROLE_KEY") or DEFAULT_KEY

        # ç§»é™¤ URL æœ«å°¾çš„æ–œæ ï¼Œé¿å…æ‹¼æ¥æ—¶å‡ºç°åŒæ–œæ 
        self.url = self.url.rstrip("/")

        # è®¾ç½®è¯·æ±‚å¤´
        self.headers = {
            "apikey": self.key,
            "Authorization": f"Bearer {self.key}",
            "Content-Type": "application/json",
            "Prefer": "return=representation"
        }

        # PostgreSQL Meta API ç«¯ç‚¹
        self.meta_api_url = f"{self.url}/pg"

        print(f"âœ… Supabase å®¢æˆ·ç«¯å·²åˆå§‹åŒ–")
        print(f"   URL: {self.url}")

    def _request(
        self,
        method: str,
        endpoint: str,
        data: Optional[Dict] = None,
        params: Optional[Dict] = None
    ) -> Dict:
        """
        å‘é€ HTTP è¯·æ±‚

        Args:
            method: HTTP æ–¹æ³• (GET, POST, PATCH, DELETE)
            endpoint: API ç«¯ç‚¹
            data: è¯·æ±‚ä½“æ•°æ®
            params: URL æŸ¥è¯¢å‚æ•°

        Returns:
            å“åº” JSON æ•°æ®
        """
        url = f"{self.url}{endpoint}"

        try:
            if method.upper() == "GET":
                response = requests.get(url, headers=self.headers, params=params, timeout=30)
            elif method.upper() == "POST":
                response = requests.post(url, headers=self.headers, json=data, params=params, timeout=30)
            elif method.upper() == "PATCH":
                response = requests.patch(url, headers=self.headers, json=data, params=params, timeout=30)
            elif method.upper() == "DELETE":
                response = requests.delete(url, headers=self.headers, params=params, timeout=30)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ HTTP æ–¹æ³•: {method}")

            response.raise_for_status()
            return response.json()

        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
            if hasattr(e, 'response') and e.response is not None:
                print(f"   å“åº”å†…å®¹: {e.response.text}")
            raise

    # ==================== è¡¨ç®¡ç† ====================

    def create_table(
        self,
        table_name: str,
        columns: List[Dict[str, Any]],
        schema: str = "public"
    ) -> Dict:
        """
        åˆ›å»ºæ•°æ®åº“è¡¨

        Args:
            table_name: è¡¨å
            columns: åˆ—å®šä¹‰åˆ—è¡¨ï¼Œæ¯ä¸ªåˆ—åŒ…å«:
                - name: åˆ—å
                - type: æ•°æ®ç±»å‹ (text, integer, bigint, numeric, boolean, timestamp, etc.)
                - isPrimaryKey: æ˜¯å¦ä¸»é”®
                - isIdentity: æ˜¯å¦è‡ªå¢
                - isNullable: æ˜¯å¦å¯ç©º
                - defaultValue: é»˜è®¤å€¼
            schema: æ¨¡å¼å (é»˜è®¤ä¸º public)

        Returns:
            åˆ›å»ºçš„è¡¨ä¿¡æ¯

        Example:
            >>> client.create_table(
            ...     "products",
            ...     [
            ...         {"name": "id", "type": "bigint", "isPrimaryKey": True, "isIdentity": True},
            ...         {"name": "name", "type": "text", "isNullable": False},
            ...         {"name": "price", "type": "numeric", "isNullable": True}
            ...     ]
            ... )
        """
        # ä½¿ç”¨ç›´æ¥ SQL æ‰§è¡Œè€Œä¸æ˜¯ postgres-meta API
        # å› ä¸º postgres-meta API çš„ /tables ç«¯ç‚¹æœ‰æ—¶ä¸èƒ½æ­£ç¡®åˆ›å»ºå­—æ®µ

        # æ„å»º SQL è¯­å¥
        column_defs = []
        for col in columns:
            col_def = f'    "{col["name"]}" {col["type"].upper()}'

            # æ·»åŠ çº¦æŸ
            if col.get("isPrimaryKey"):
                col_def += " PRIMARY KEY"

            if col.get("isIdentity"):
                # å¯¹äº PostgreSQLï¼Œä½¿ç”¨ SERIAL æˆ– BIGSERIAL
                if col["type"].lower() in ["integer", "int"]:
                    col_def = f'    "{col["name"]}" SERIAL PRIMARY KEY'
                elif col["type"].lower() in ["bigint", "big integer"]:
                    col_def = f'    "{col["name"]}" BIGSERIAL PRIMARY KEY'
                else:
                    col_def += " GENERATED BY DEFAULT AS IDENTITY"

            if not col.get("isNullable", False) and not col.get("isPrimaryKey"):
                col_def += " NOT NULL"

            if col.get("defaultValue"):
                default_val = col["defaultValue"]
                # å¤„ç†ç‰¹æ®Šçš„é»˜è®¤å€¼
                if default_val == "now()":
                    col_def += " DEFAULT NOW()"
                elif isinstance(default_val, str) and not default_val.isdigit():
                    col_def += f" DEFAULT '{default_val}'"
                else:
                    col_def += f" DEFAULT {default_val}"

            column_defs.append(col_def)

        # æ„å»ºå®Œæ•´çš„ CREATE TABLE è¯­å¥
        full_table_name = f'"{schema}"."{table_name}"' if schema != "public" else f'"{table_name}"'
        sql = f"CREATE TABLE {full_table_name} (\n" + ",\n".join(column_defs) + "\n);"

        print(f"ğŸ”§ æ­£åœ¨åˆ›å»ºè¡¨ '{table_name}'...")

        # ä½¿ç”¨ postgres-meta çš„ query ç«¯ç‚¹æ‰§è¡Œ SQL
        response = requests.post(
            f"{self.meta_api_url}/query",
            headers=self.headers,
            json={"query": sql}
        )
        response.raise_for_status()

        print(f"âœ… è¡¨ '{table_name}' åˆ›å»ºæˆåŠŸ")

        # ç­‰å¾… PostgREST åˆ·æ–° schema cache
        print("â³ ç­‰å¾… PostgREST åˆ·æ–° schema cache...")
        import time
        time.sleep(3)

        return {"table_name": table_name, "columns": columns}

    def list_tables(self, schema: str = "public") -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰è¡¨"""
        response = requests.get(
            f"{self.meta_api_url}/tables",
            headers=self.headers,
            params={"schema": schema}
        )
        response.raise_for_status()
        return response.json()

    def get_table_info(self, table_name: str, schema: str = "public") -> Dict:
        """è·å–è¡¨è¯¦ç»†ä¿¡æ¯"""
        response = requests.get(
            f"{self.meta_api_url}/tables/{schema}.{table_name}",
            headers=self.headers
        )
        response.raise_for_status()
        return response.json()

    def drop_table(self, table_name: str, schema: str = "public", cascade: bool = False) -> Dict:
        """åˆ é™¤è¡¨"""
        response = requests.delete(
            f"{self.meta_api_url}/tables/{schema}.{table_name}",
            headers=self.headers,
            params={"cascade": cascade}
        )
        response.raise_for_status()
        print(f"âœ… è¡¨ '{table_name}' åˆ é™¤æˆåŠŸ")
        return response.json()

    def add_column(
        self,
        table_name: str,
        column: Dict[str, Any],
        schema: str = "public"
    ) -> Dict:
        """
        æ·»åŠ åˆ—åˆ°è¡¨

        Args:
            table_name: è¡¨å
            column: åˆ—å®šä¹‰ (æ ¼å¼åŒ create_table çš„ columns)
            schema: æ¨¡å¼å
        """
        response = requests.post(
            f"{self.meta_api_url}/tables/{schema}.{table_name}/columns",
            headers=self.headers,
            json=column
        )
        response.raise_for_status()
        print(f"âœ… åˆ— '{column['name']}' æ·»åŠ åˆ°è¡¨ '{table_name}'")
        return response.json()

    def alter_column(
        self,
        table_name: str,
        column_name: str,
        alterations: Dict[str, Any],
        schema: str = "public"
    ) -> Dict:
        """
        ä¿®æ”¹åˆ—

        Args:
            table_name: è¡¨å
            column_name: åˆ—å
            alterations: è¦ä¿®æ”¹çš„å­—æ®µï¼Œå¦‚ {"nullable": False, "default": "0"}
            schema: æ¨¡å¼å
        """
        response = requests.patch(
            f"{self.meta_api_url}/tables/{schema}.{table_name}/columns/{column_name}",
            headers=self.headers,
            json=alterations
        )
        response.raise_for_status()
        print(f"âœ… åˆ— '{column_name}' ä¿®æ”¹æˆåŠŸ")
        return response.json()

    def drop_column(
        self,
        table_name: str,
        column_name: str,
        schema: str = "public"
    ) -> Dict:
        """åˆ é™¤åˆ—"""
        response = requests.delete(
            f"{self.meta_api_url}/tables/{schema}.{table_name}/columns/{column_name}",
            headers=self.headers
        )
        response.raise_for_status()
        print(f"âœ… åˆ— '{column_name}' åˆ é™¤æˆåŠŸ")
        return response.json()

    # ==================== æ•°æ® CRUD ====================

    def insert(
        self,
        table_name: str,
        data: Union[Dict, List[Dict]],
        schema: str = "public"
    ) -> List[Dict]:
        """
        æ’å…¥æ•°æ®

        Args:
            table_name: è¡¨å
            data: è¦æ’å…¥çš„æ•°æ® (å•æ¡è®°å½•æˆ–è®°å½•åˆ—è¡¨)
            schema: æ¨¡å¼å

        Returns:
            æ’å…¥çš„è®°å½•
        """
        endpoint = f"/rest/v1/{table_name}"
        headers = self.headers.copy()
        headers["Prefer"] = "return=representation"

        is_single = not isinstance(data, list)
        payload = data if is_single else data

        url = f"{self.url}{endpoint}"
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()

        result = response.json()
        if is_single:
            result = [result]

        print(f"âœ… æ’å…¥ {len(result)} æ¡è®°å½•åˆ° '{table_name}'")
        return result

    def select(
        self,
        table_name: str,
        columns: str = "*",
        filters: Optional[Dict[str, Any]] = None,
        order: Optional[str] = None,
        limit: Optional[int] = None,
        offset: Optional[int] = None,
        schema: str = "public"
    ) -> List[Dict]:
        """
        æŸ¥è¯¢æ•°æ®

        Args:
            table_name: è¡¨å
            columns: è¦æŸ¥è¯¢çš„åˆ—ï¼Œé»˜è®¤ "*"
            filters: è¿‡æ»¤æ¡ä»¶ï¼Œå¦‚ {"id": "eq.1", "name": "like.%test%"}
            order: æ’åºï¼Œå¦‚ "id.desc" æˆ– "name.asc"
            limit: é™åˆ¶è¿”å›æ•°é‡
            offset: åç§»é‡
            schema: æ¨¡å¼å

        Returns:
            æŸ¥è¯¢ç»“æœåˆ—è¡¨

        Example:
            >>> client.select(
            ...     "products",
            ...     filters={"price": "gte.100"},
            ...     order="created_at.desc",
            ...     limit=10
            ... )
        """
        endpoint = f"/rest/v1/{table_name}"
        params = {"select": columns}

        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filters:
            for key, value in filters.items():
                params[key] = value

        # æ·»åŠ æ’åº
        if order:
            params["order"] = order

        # æ·»åŠ åˆ†é¡µ
        if limit:
            params["limit"] = limit
        if offset:
            params["offset"] = offset

        url = f"{self.url}{endpoint}"
        response = requests.get(url, headers=self.headers, params=params)
        response.raise_for_status()

        result = response.json()
        print(f"âœ… æŸ¥è¯¢åˆ° {len(result)} æ¡è®°å½•")
        return result

    def update(
        self,
        table_name: str,
        data: Dict[str, Any],
        filters: Dict[str, Any],
        schema: str = "public"
    ) -> List[Dict]:
        """
        æ›´æ–°æ•°æ®

        Args:
            table_name: è¡¨å
            data: è¦æ›´æ–°çš„æ•°æ®
            filters: è¿‡æ»¤æ¡ä»¶ (å¿…é¡»)
            schema: æ¨¡å¼å

        Returns:
            æ›´æ–°çš„è®°å½•
        """
        endpoint = f"/rest/v1/{table_name}"
        headers = self.headers.copy()
        headers["Prefer"] = "return=representation"

        # å°† filters è½¬ä¸ºæŸ¥è¯¢å‚æ•°
        params = {}
        for key, value in filters.items():
            params[key] = value

        url = f"{self.url}{endpoint}"
        response = requests.patch(url, headers=headers, json=data, params=params)
        response.raise_for_status()

        result = response.json()
        print(f"âœ… æ›´æ–°äº† {len(result)} æ¡è®°å½•")
        return result

    def delete(
        self,
        table_name: str,
        filters: Dict[str, Any],
        schema: str = "public"
    ) -> List[Dict]:
        """
        åˆ é™¤æ•°æ®

        Args:
            table_name: è¡¨å
            filters: è¿‡æ»¤æ¡ä»¶ (å¿…é¡»)
            schema: æ¨¡å¼å

        Returns:
            åˆ é™¤çš„è®°å½•
        """
        endpoint = f"/rest/v1/{table_name}"
        headers = self.headers.copy()
        headers["Prefer"] = "return=representation"

        # å°† filters è½¬ä¸ºæŸ¥è¯¢å‚æ•°
        params = {}
        for key, value in filters.items():
            params[key] = value

        url = f"{self.url}{endpoint}"
        response = requests.delete(url, headers=headers, params=params)
        response.raise_for_status()

        result = response.json()
        print(f"âœ… åˆ é™¤äº† {len(result)} æ¡è®°å½•")
        return result

    def count(
        self,
        table_name: str,
        filters: Optional[Dict[str, Any]] = None,
        column: str = "*",
        schema: str = "public"
    ) -> int:
        """
        ç»Ÿè®¡è®°å½•æ•°

        Args:
            table_name: è¡¨å
            filters: è¿‡æ»¤æ¡ä»¶
            column: ç»Ÿè®¡çš„åˆ— (é»˜è®¤ *)
            schema: æ¨¡å¼å

        Returns:
            è®°å½•æ•°
        """
        endpoint = f"/rest/v1/{table_name}"
        headers = {
            "apikey": self.key,
            "Authorization": f"Bearer {self.key}",
            "Prefer": "count=exact"
        }

        params = {}
        if filters:
            for key, value in filters.items():
                params[key] = value

        url = f"{self.url}{endpoint}"
        response = requests.get(url, headers=headers, params=params)
        response.raise_for_status()

        count = int(response.headers.get("Content-Range", "0").split("/")[1])
        print(f"âœ… è¡¨ '{table_name}' ä¸­æœ‰ {count} æ¡è®°å½•")
        return count

    # ==================== SQL æŸ¥è¯¢ ====================

    def execute_sql(self, sql: str) -> List[Dict]:
        """
        æ‰§è¡Œ SQL æŸ¥è¯¢

        Args:
            sql: SQL æŸ¥è¯¢è¯­å¥

        Returns:
            æŸ¥è¯¢ç»“æœ

        Example:
            >>> client.execute_sql("SELECT * FROM products WHERE price > 100")
        """
        endpoint = "/rest/v1/rpc/exec_sql"
        url = f"{self.url}{endpoint}"
        response = requests.post(
            url,
            headers=self.headers,
            json={"query": sql}
        )

        # å¦‚æœ exec_sql ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨ alternative approach
        if response.status_code == 404:
            print("âš ï¸  exec_sql å‡½æ•°ä¸å­˜åœ¨ï¼Œè¯·å…ˆåœ¨æ•°æ®åº“ä¸­åˆ›å»ºè¯¥å‡½æ•°")
            print("   å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ SQL åˆ›å»º:")
            print("""
            CREATE OR REPLACE FUNCTION exec_sql(query text)
            RETURNS SETOF json
            LANGUAGE plpgsql
            AS $$
            BEGIN
                RETURN QUERY EXECUTE query;
            END;
            $$;
            """)
            response.raise_for_status()

        response.raise_for_status()
        result = response.json()
        print(f"âœ… SQL æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œè¿”å› {len(result)} æ¡è®°å½•")
        return result

    # ==================== æ•°æ®å¯¼å…¥å¯¼å‡º ====================

    def export_to_csv(
        self,
        table_name: str,
        output_file: str,
        filters: Optional[Dict[str, Any]] = None,
        schema: str = "public"
    ) -> int:
        """
        å¯¼å‡ºæ•°æ®åˆ° CSV æ–‡ä»¶

        Args:
            table_name: è¡¨å
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            filters: è¿‡æ»¤æ¡ä»¶
            schema: æ¨¡å¼å

        Returns:
            å¯¼å‡ºçš„è®°å½•æ•°
        """
        data = self.select(table_name, filters=filters, schema=schema)

        if not data:
            print(f"âš ï¸  è¡¨ '{table_name}' ä¸­æ²¡æœ‰æ•°æ®")
            return 0

        # è·å–æ‰€æœ‰å­—æ®µ
        fieldnames = list(data[0].keys())

        with open(output_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(data)

        print(f"âœ… å¯¼å‡º {len(data)} æ¡è®°å½•åˆ° '{output_file}'")
        return len(data)

    def import_from_csv(
        self,
        table_name: str,
        input_file: str,
        schema: str = "public",
        batch_size: int = 1000
    ) -> int:
        """
        ä» CSV æ–‡ä»¶å¯¼å…¥æ•°æ®

        Args:
            table_name: è¡¨å
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            schema: æ¨¡å¼å
            batch_size: æ‰¹é‡æ’å…¥å¤§å°

        Returns:
            å¯¼å…¥çš„è®°å½•æ•°
        """
        with open(input_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            data = list(reader)

        if not data:
            print(f"âš ï¸  CSV æ–‡ä»¶ '{input_file}' ä¸­æ²¡æœ‰æ•°æ®")
            return 0

        # æ‰¹é‡æ’å…¥
        total = 0
        for i in range(0, len(data), batch_size):
            batch = data[i:i + batch_size]
            # å°†å­—ç¬¦ä¸²å€¼è½¬æ¢ä¸ºé€‚å½“ç±»å‹
            converted_batch = []
            for row in batch:
                converted_row = {}
                for key, value in row.items():
                    # å°è¯•è½¬æ¢ä¸ºæ•°å­—
                    if value and value.replace('.', '', 1).replace('-', '', 1).isdigit():
                        converted_row[key] = float(value) if '.' in value else int(value)
                    else:
                        converted_row[key] = value
                converted_batch.append(converted_row)

            self.insert(table_name, converted_batch, schema=schema)
            total += len(converted_batch)

        print(f"âœ… ä» '{input_file}' å¯¼å…¥ {total} æ¡è®°å½•")
        return total

    def export_to_json(
        self,
        table_name: str,
        output_file: str,
        filters: Optional[Dict[str, Any]] = None,
        schema: str = "public"
    ) -> int:
        """
        å¯¼å‡ºæ•°æ®åˆ° JSON æ–‡ä»¶

        Args:
            table_name: è¡¨å
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            filters: è¿‡æ»¤æ¡ä»¶
            schema: æ¨¡å¼å

        Returns:
            å¯¼å‡ºçš„è®°å½•æ•°
        """
        data = self.select(table_name, filters=filters, schema=schema)

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2, default=str)

        print(f"âœ… å¯¼å‡º {len(data)} æ¡è®°å½•åˆ° '{output_file}'")
        return len(data)

    def import_from_json(
        self,
        table_name: str,
        input_file: str,
        schema: str = "public",
        batch_size: int = 1000
    ) -> int:
        """
        ä» JSON æ–‡ä»¶å¯¼å…¥æ•°æ®

        Args:
            table_name: è¡¨å
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            schema: æ¨¡å¼å
            batch_size: æ‰¹é‡æ’å…¥å¤§å°

        Returns:
            å¯¼å…¥çš„è®°å½•æ•°
        """
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        if not isinstance(data, list):
            data = [data]

        if not data:
            print(f"âš ï¸  JSON æ–‡ä»¶ '{input_file}' ä¸­æ²¡æœ‰æ•°æ®")
            return 0

        # æ‰¹é‡æ’å…¥
        total = 0
        for i in range(0, len(data), batch_size):
            batch = data[i:i + batch_size]
            self.insert(table_name, batch, schema=schema)
            total += len(batch)

        print(f"âœ… ä» '{input_file}' å¯¼å…¥ {total} æ¡è®°å½•")
        return total


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description="Supabase å®¢æˆ·ç«¯å‘½ä»¤è¡Œå·¥å…·")
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # åˆ—è¡¨å‘½ä»¤
    list_parser = subparsers.add_parser("list", help="åˆ—å‡ºæ‰€æœ‰è¡¨")
    list_parser.add_argument("--schema", default="public", help="æ¨¡å¼å")

    # è¡¨ä¿¡æ¯å‘½ä»¤
    info_parser = subparsers.add_parser("info", help="è·å–è¡¨ä¿¡æ¯")
    info_parser.add_argument("table", help="è¡¨å")
    info_parser.add_argument("--schema", default="public", help="æ¨¡å¼å")

    # æŸ¥è¯¢å‘½ä»¤
    select_parser = subparsers.add_parser("select", help="æŸ¥è¯¢æ•°æ®")
    select_parser.add_argument("table", help="è¡¨å")
    select_parser.add_argument("--columns", default="*", help="åˆ—å")
    select_parser.add_argument("--filter", help="è¿‡æ»¤æ¡ä»¶ (JSON)")
    select_parser.add_argument("--limit", type=int, help="é™åˆ¶æ•°é‡")
    select_parser.add_argument("--schema", default="public", help="æ¨¡å¼å")

    # æ’å…¥å‘½ä»¤
    insert_parser = subparsers.add_parser("insert", help="æ’å…¥æ•°æ®")
    insert_parser.add_argument("table", help="è¡¨å")
    insert_parser.add_argument("data", help="æ•°æ® (JSON)")
    insert_parser.add_argument("--schema", default="public", help="æ¨¡å¼å")

    # SQL å‘½ä»¤
    sql_parser = subparsers.add_parser("sql", help="æ‰§è¡Œ SQL")
    sql_parser.add_argument("query", help="SQL æŸ¥è¯¢")

    # å¯¼å‡ºå‘½ä»¤
    export_parser = subparsers.add_parser("export", help="å¯¼å‡ºæ•°æ®")
    export_parser.add_argument("table", help="è¡¨å")
    export_parser.add_argument("output", help="è¾“å‡ºæ–‡ä»¶")
    export_parser.add_argument("--format", choices=["csv", "json"], default="csv", help="æ–‡ä»¶æ ¼å¼")
    export_parser.add_argument("--schema", default="public", help="æ¨¡å¼å")

    # å¯¼å…¥å‘½ä»¤
    import_parser = subparsers.add_parser("import", help="å¯¼å…¥æ•°æ®")
    import_parser.add_argument("table", help="è¡¨å")
    import_parser.add_argument("input", help="è¾“å…¥æ–‡ä»¶")
    import_parser.add_argument("--schema", default="public", help="æ¨¡å¼å")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = SupabaseClient()

    # æ‰§è¡Œå‘½ä»¤
    if args.command == "list":
        tables = client.list_tables(schema=args.schema)
        print("\nğŸ“‹ æ•°æ®åº“è¡¨åˆ—è¡¨:")
        for table in tables:
            print(f"  - {table['name']}")
        print(f"\nå…± {len(tables)} ä¸ªè¡¨")

    elif args.command == "info":
        info = client.get_table_info(args.table, schema=args.schema)
        print(f"\nğŸ“‹ è¡¨ '{args.table}' ä¿¡æ¯:")
        print(json.dumps(info, indent=2, ensure_ascii=False))

    elif args.command == "select":
        filters = json.loads(args.filter) if args.filter else None
        data = client.select(
            args.table,
            columns=args.columns,
            filters=filters,
            limit=args.limit,
            schema=args.schema
        )
        print("\nğŸ“‹ æŸ¥è¯¢ç»“æœ:")
        print(json.dumps(data, indent=2, ensure_ascii=False))

    elif args.command == "insert":
        data = json.loads(args.data)
        client.insert(args.table, data, schema=args.schema)

    elif args.command == "sql":
        result = client.execute_sql(args.query)
        print("\nğŸ“‹ æŸ¥è¯¢ç»“æœ:")
        print(json.dumps(result, indent=2, ensure_ascii=False))

    elif args.command == "export":
        if args.format == "csv":
            client.export_to_csv(args.table, args.output, schema=args.schema)
        else:
            client.export_to_json(args.table, args.output, schema=args.schema)

    elif args.command == "import":
        if args.input.endswith(".csv"):
            client.import_from_csv(args.table, args.input, schema=args.schema)
        else:
            client.import_from_json(args.table, args.input, schema=args.schema)


if __name__ == "__main__":
    main()
